{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9axA6bwRLMs"
   },
   "source": [
    "# CS5660 Final Project\n",
    "## Topic Modeling on arXiv abstract data\n",
    "Ryan Dielhenn  \n",
    "Joe Jimenez  \n",
    "Bohdan Hrotovytskyy  \n",
    "Ryan Goshorn  \n",
    "CalStateLA\n",
    "\n",
    "## Topic Modeling\n",
    "\n",
    "### Def 1.\n",
    "**Topic modeling** is an **unsupervised machine learning technique** that automatically identifies the abstract topics present within a collection of documents. It assumes that each document is a mixture of a small number of topics and that each topic is characterized by a distribution over words. The goal of topic modeling is to uncover the hidden thematic structure in large textual datasets, facilitating tasks such as organization, summarization, and discovery of patterns without prior annotation.\n",
    "\n",
    "### Def 2.\n",
    "* The problem of modeling text corpora and other collections of discrete data. The goal is to find short descriptions of the members of a collection that enable efficient processing of large collections while preserving the essential statistical relationships that are useful for basic tasks such as classification, novelty detection, summarization, and similarity and relevance judgments.\n",
    "\n",
    "\n",
    "[1] Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of machine Learning research, 3(Jan), 993-1022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xR4qmlDJRLMt"
   },
   "source": [
    "### Traditional Topic Models and Their Limitation\n",
    "\n",
    "* Traditional Approaches:\n",
    "    * Latent Dirichlet Allocation (LDA)\n",
    "    * Non-Negative Matrix Factorization (NMF)\n",
    "\n",
    "* Bag-of-Words Assumption\n",
    "    * Treat documents as a collection of individual words (e.g., ignores word order).\n",
    "\n",
    "* Limitation:\n",
    "    * Ignores the meaning and relationship between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0LORjd5RLMt"
   },
   "source": [
    "### What is a Bag-of-Words?\n",
    "* A bag-of-words is a representation of text that describes the occurrence of words within a document.\n",
    "    \n",
    "    * A vocabulary\n",
    "    * A measure of the presence of known words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4xUxfjG4GM3"
   },
   "source": [
    "# Project: Topic Modeling arXiv cs.AI with BERTopic and LLMs\n",
    "\n",
    "## Goal\n",
    "Discover the main research themes in the **cs.AI** category on arXiv by:\n",
    "- Grouping similar paper abstracts into topics\n",
    "- Automatically generating human-readable labels for each topic\n",
    "- Visualizing how topics relate to each other\n",
    "\n",
    "## Methods (High-Level)\n",
    "- **Bag-of-Words demo:** Simple example to introduce topic modeling.\n",
    "- **BERTopic:** Uses sentence embeddings + UMAP + HDBSCAN to create dense, meaningful clusters.\n",
    "- **LLM labeling (Llama3 via Ollama):** Generates concise, human-style topic names from keywords and representative documents.\n",
    "- **Visualization:**\n",
    "  - Intertopic distance maps\n",
    "  - Topic word score bar charts\n",
    "  - Document map scatter plots\n",
    "  - Final radial topic map (DataMapPlot)\n",
    "\n",
    "## Dataset\n",
    "- Source: arXiv API, category **cs.AI**\n",
    "- Data: ~1000 paper abstracts (title + abstract text)\n",
    "- Use case: Explore what kinds of AI research areas are most common in this category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1764123354831,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "PRZGM_MJvJYV",
    "outputId": "b6412a63-31a8-4c45-d541-07e38147df15"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from typing import List\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentence = [\"John likes to watch movies. Mary likes movies too.\"]\n",
    "\n",
    "\n",
    "def print_bow(sentence: List[str]) -> None:\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentence)\n",
    "    sequences = tokenizer.texts_to_sequences(sentence)\n",
    "    word_index = tokenizer.word_index\n",
    "    bow = {}\n",
    "    for key in word_index:\n",
    "        bow[key] = sequences[0].count(word_index[key])\n",
    "\n",
    "    print(f\"Bag of word sentence 1:\\n{bow}\")\n",
    "    print(f\"{word_index}\")\n",
    "    print(f\"We found {len(word_index)} unique tokens.\")\n",
    "\n",
    "\n",
    "print_bow(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1764123354834,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "f7VL5gtsvSy0",
    "outputId": "1b8f33ea-1b74-4a83-b982-dfeaf6e58b34"
   },
   "outputs": [],
   "source": [
    "print(\"John likes to watch movies. Mary likes movies too.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH7na1tIRLMt"
   },
   "source": [
    "### BERTopic [(ðŸ”—)](https://maartengr.github.io/BERTopic/index.html)\n",
    "BERTopic is a topic modeling technique that leverages ðŸ¤— transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
    "\n",
    "### Visual Overview\n",
    "\n",
    "BERTopic can be viewed as a sequence of steps to create its topic representations. BERTopic generates topics from text through a four-step process:\n",
    "\n",
    "1. **Embedding**: Each document is first transformed into a numerical vector using a pre-trained language model such as BERT. This step captures the semantic meaning and contextual nuances of the text.\n",
    "\n",
    "2. **Dimensionality Reduction**: Because the resulting vectors are high-dimensional, a dimensionality reduction technique (e.g., UMAP) is applied to simplify the representation while preserving important structure, making clustering more efficient and effective.\n",
    "\n",
    "3. **Clustering**: The reduced vectors are then clustered into groups, where each cluster corresponds to a potential topic.\n",
    "\n",
    "4. **Topic Representation**: For each cluster, BERTopic applies a technique called class-based TF-IDF to identify the key words that best characterize the topic.\n",
    "\n",
    "This end-to-end process enables BERTopic to generate clear, interpretable, and contextually rich topics, often outperforming traditional topic modeling methods.\n",
    "\n",
    "![image.png](attachment:6c85ca13-6cfa-4a64-9443-bbe4b29e41c2.png)![image.png](attachment:4a208f14-75db-4b07-acb8-c0998be65fe9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oronUo91z0zK"
   },
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20833,
     "status": "ok",
     "timestamp": 1764123375666,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "MaDCcduy8iG5",
    "outputId": "3c4eb587-e4af-451f-8e5a-3b9857365c38"
   },
   "outputs": [],
   "source": [
    "# BERTopic library\n",
    "!pip install -q BERTopic\n",
    "\n",
    "# Visualization Libraries\n",
    "!pip install datamapplot matplotlib\n",
    "\n",
    "# Tokenization and ollama for running llm locally\n",
    "!pip install -q openai tiktoken ollama\n",
    "\n",
    "# Cuda Drivers for running LLM on colab\n",
    "!apt-get update && apt-get install -y pciutils cuda-drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JetXAq7z6Z_"
   },
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 10449,
     "status": "error",
     "timestamp": 1764123386118,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "rNaWS2IizN44",
    "outputId": "c572d4b0-d742-4bae-8dfe-5359818fe680"
   },
   "outputs": [],
   "source": [
    "# Core\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import subprocess\n",
    "import ast\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Topic modeling\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import (\n",
    "    KeyBERTInspired,\n",
    "    MaximalMarginalRelevance,\n",
    "    TextGeneration,\n",
    "    OpenAI as RepresentationOpenAI\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import datamapplot\n",
    "\n",
    "# External services\n",
    "from google.colab import drive\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "# Mount Google Drive to access files\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Utilities for fetching abstracts from the arXiv api\n",
    "sys.path.insert(0, \"/content/drive/MyDrive/CSULA/CS5660/arXiv_topic_modeling\")\n",
    "from utils import fetch_arxiv_abstracts\n",
    "print(\"âœ… Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN9WpI8KRLMu"
   },
   "source": [
    "## BERTopic Quick Start\n",
    "\n",
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1764123386135,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "7BlZOPOEEwsR"
   },
   "outputs": [],
   "source": [
    "docs, titles = fetch_arxiv_abstracts(category='cs.AI', max_results=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31437,
     "status": "aborted",
     "timestamp": 1764123386136,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "__caSuMD8wYB"
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQuAsXuSRLMu"
   },
   "source": [
    "`fetch_arXiv_abstracts` is a function from `utils/` that will return a certain number of abstracts from a category eg `cs.AI`. The arXiv api seems to have rate limiting so we may need a delay before fetching more data in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwOxwGLZRLMu"
   },
   "source": [
    "### Building and Training the BERTopic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1764123386138,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "GIqL7aMGRLMu"
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSgmkjv6RLMu"
   },
   "source": [
    "After generating topics and their probabilities, we can access the frequent topics that were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31436,
     "status": "aborted",
     "timestamp": 1764123386139,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "tBoqMES8cg8D"
   },
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjaGPCVich-d"
   },
   "source": [
    "* -1 refers to all outliers and should typically be ignored.\n",
    "* Next, let's take a look at the most frequent topic that was generated, topic 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31435,
     "status": "aborted",
     "timestamp": 1764123386141,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "zYrvuDrzcp2I"
   },
   "outputs": [],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVnVbAn_eN0B"
   },
   "source": [
    "Using `.get_document_info`, we can also extract information on a document level, such as their corresponding topics, probabilities, whether they are representative documents for a topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31435,
     "status": "aborted",
     "timestamp": 1764123386143,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "OlAsssGfeOVe"
   },
   "outputs": [],
   "source": [
    "topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzMRIU4cRLMv"
   },
   "source": [
    " ### Representation Models: Fine-tune Topic Representation\n",
    "\n",
    "BERTopic uses a Bag-of-Words approach with class-based TF-IDF (c-TF-IDF) to quickly generate topic keywords without needing to re-train the model after clustering.\n",
    "While this provides good initial topic representations, BERTopic also offers optional representation models for further fine-tuning.\n",
    "These models can range from powerful GPT-like models to faster keyword extraction methods like KeyBERT, giving users flexibility to enhance topic quality as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5MaTsy3RLMv"
   },
   "source": [
    "### LLM & Generative AI\n",
    "\n",
    "Using LLMs such as GPT-4, and open source soultion, we can fine-tune topics to generate labels, summaries of the topics.\n",
    "\n",
    "- Generate a set of keywords and documetns that describe a topic best using BERTopic's c-TF-IDF .\n",
    "- Candidate keywords and documents are passed to the text generation model and asked to generate output that fits the topic best.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OatGS1vuRLMv"
   },
   "source": [
    "#### Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1764123386147,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "qzRLf3TGRLMv"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I have topic that contains the following documents: \\n[DOCUMENTS]\n",
    "The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "Based on the above information, can you give a short label of the topic?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg6s-1ULRLMv"
   },
   "source": [
    "### Selecting Documents\n",
    "\n",
    "Four of the most representative documents will be passed to `[Documents]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J5MztY-RLMv"
   },
   "source": [
    "BERTopic works rather straightforward. It consists of 5 sequential steps: embedding documents, reducing embeddings in dimensionality, cluster embeddings, tokenize documents per cluster, and finally extract the best representing words per topic.\n",
    "<br>\n",
    "<div>\n",
    "<img src=\"https://github.com/MaartenGr/BERTopic/assets/25746895/e9b0d8cf-2e19-4bf1-beb4-4ff2d9fa5e2d\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1764123386148,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "xMX28Q9Tj7TO"
   },
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.ai/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1764123386149,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "jEFu_kj5kznq"
   },
   "outputs": [],
   "source": [
    "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
    "\n",
    "def run_ollama_serve():\n",
    "    subprocess.Popen([\"nohup\", \"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "run_ollama_serve()\n",
    "time.sleep(5)\n",
    "print(\"Ollama server started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1764123386150,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "iFsrgwUuk1Tq"
   },
   "outputs": [],
   "source": [
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1764123386151,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "R3HqnuLJmDPz",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Configure the client to use the local Ollama server\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',\n",
    "    api_key='ollama', # dummy API key required by the client library\n",
    ")\n",
    "\n",
    "# Use the model you pulled (e.g., \"llama3\")\n",
    "model_name = \"llama3\"\n",
    "\n",
    "print(f\"Sending request to {model_name}...\")\n",
    "\n",
    "# Example using the standard OpenAI client chat completion\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Explain how to run an LLM locally in one sentence.\"}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    print(\"\\n--- Model Response ---\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"----------------------\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "    print(\"Make sure the 'ollama serve' process is running in the background.\")\n",
    "\n",
    "# You can run !ollama ps again after this code executes to see the model usage\n",
    "time.sleep(2)\n",
    "!ollama ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1764123386152,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "o3tNrNtORLMv"
   },
   "outputs": [],
   "source": [
    "!curl http://localhost:11434/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1764123386153,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "qckIktwOtTjS"
   },
   "outputs": [],
   "source": [
    "# Assuming bertopic and its dependencies are installed\n",
    "# If not, run this line first: !pip install bertopic sentence-transformers\n",
    "\n",
    "prompt = \"\"\"\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "Generate a concise topic label (3-7 words) that captures the main theme.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "- Output ONLY the topic label itself\n",
    "- Do NOT include phrases like \"Here is\", \"The topic is\", \"Topic:\", or any preamble\n",
    "- Do NOT add explanations or formatting\n",
    "- Just output the label directly as plain text\n",
    "\n",
    "Example output: \"Neural Networks for Computer Vision\"\n",
    "\n",
    "Your label:\"\"\"\n",
    "\n",
    "# Configure the client to use the local Ollama server\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama_key_placeholder\",\n",
    ")\n",
    "\n",
    "# Use the model you pulled (e.g., \"llama3\")\n",
    "OLLAMA_MODEL_NAME = \"llama3\"\n",
    "ollama_representation_model = RepresentationOpenAI(client, prompt=prompt, model=OLLAMA_MODEL_NAME, delay_in_seconds=10)\n",
    "\n",
    "print(f\"Representation model configured using local Ollama model: {OLLAMA_MODEL_NAME}\")\n",
    "\n",
    "# You can now proceed with your BERTopic workflow:\n",
    "# topic_model = BERTopic(representation_model=representation_model)\n",
    "# documents = [...] # Your actual list of documents\n",
    "# topics, probabilites = topic_model.fit_transform(documents)\n",
    "\n",
    "# Verification using a simple prompt\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=OLLAMA_MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Confirm that you are running locally via Ollama.\"}\n",
    "        ],\n",
    "    )\n",
    "    print(\"\\n--- Verification Response ---\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"-----------------------------\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during verification: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KMup1RxRLMv"
   },
   "source": [
    "## **Preparing Embeddings**\n",
    "\n",
    "By pre-calculating the embeddings for each document, we can speed-up additional exploration steps and use the embeddings to quickly iterate over BERTopic's hyperparameters if needed.\n",
    "\n",
    "ðŸ”¥ **TIP**: You can find a great overview of good embeddings for clustering on the [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31433,
     "status": "aborted",
     "timestamp": 1764123386153,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "ehxoHWOsRLMv"
   },
   "outputs": [],
   "source": [
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31433,
     "status": "aborted",
     "timestamp": 1764123386154,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "nA_gAwY4RLMv"
   },
   "outputs": [],
   "source": [
    "#Pre-reduce embeddings for visualization purposes\n",
    "reduced_embeddings = UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine', random_state=42).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31433,
     "status": "aborted",
     "timestamp": 1764123386156,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "lgD6_z03RLMv"
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame({\n",
    "    \"x1\": [point[0] for point in reduced_embeddings],\n",
    "    \"x2\": [point[1] for point in reduced_embeddings],\n",
    "    \"docs\": docs,\n",
    "})\n",
    "\n",
    "df_plot[\"docs_short\"] = df_plot[\"docs\"].str[:100] + \"...\"\n",
    "df_plot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31432,
     "status": "aborted",
     "timestamp": 1764123386157,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "XaVgK4awRLMv"
   },
   "outputs": [],
   "source": [
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "total_docs = len(df_plot)\n",
    "fig = px.scatter(df_plot, x=\"x1\", y=\"x2\",  hover_data=[\"docs_short\"])\n",
    "fig.update_traces(marker=dict(line=dict(width=0.5, color='white')))\n",
    "fig.update_layout(\n",
    "    title=f\"arXiv abstracts from cs.AI - Document Map ({total_docs} documents)\",\n",
    "    title_font_size=20\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5Bw6Xx3RLMv"
   },
   "source": [
    "## **Sub-models**\n",
    "\n",
    "Next, we will define all sub-models in BERTopic and do some small tweaks to the number of clusters to be created, setting random states, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31432,
     "status": "aborted",
     "timestamp": 1764123386158,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "2V1o0kcLRLMv"
   },
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb46htIKRLMv"
   },
   "source": [
    "As a small bonus, we are going to reduce the embeddings we created before to 2-dimensions so that we can use them for visualization purposes when we have created our topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdZCvn2LRLMv"
   },
   "source": [
    "### **Representation Models**\n",
    "\n",
    "One of the ways we are going to represent the topics is with Llama 2 which should give us a nice label. However, we might want to have additional representations to view a topic from multiple angles.\n",
    "\n",
    "Here, we will be using c-TF-IDF as our main representation and [KeyBERT](https://maartengr.github.io/BERTopic/getting_started/representation/representation.html#keybertinspired), [MMR](https://maartengr.github.io/BERTopic/getting_started/representation/representation.html#maximalmarginalrelevance), and [Llama 2](https://maartengr.github.io/BERTopic/getting_started/representation/llm.html) as our additional representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31431,
     "status": "aborted",
     "timestamp": 1764123386159,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "4ccdqNWMRLMv"
   },
   "outputs": [],
   "source": [
    "# KeyBERT\n",
    "keybert = KeyBERTInspired()\n",
    "\n",
    "# MMR\n",
    "mmr = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "# Text generation with Llama 2\n",
    "#llama2 = TextGeneration(generator, prompt=prompt)\n",
    "\n",
    "# All representation models\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert,\n",
    "    \"GPT-40\": ollama_representation_model, # Use the renamed object\n",
    "    \"MMR\": mmr,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GX2VIltRLMw"
   },
   "source": [
    "# **Training**\n",
    "\n",
    "Now that we have our models prepared, we can start training our topic model! We supply BERTopic with the sub-models of interest, run `.fit_transform`, and see what kind of topics we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Awk5apAPRLM3"
   },
   "source": [
    "## Multiple Representations\n",
    "During the development of BERTopic, many different types of representations can be created, from keywords and phrases to summaries and custom labels. There is a variety of techniques that one can choose from to represent a topic. As such, there are a number of interesting and creative ways one can summarize topics. A topic is more than just a single representation.\n",
    "\n",
    "Therefore, multi-aspect topic modeling is introduced! During the .fit or .fit_transform stages, you can now get multiple representations of a single topic. In practice, it works by generating and storing all kinds of different topic representations (see image below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31430,
     "status": "aborted",
     "timestamp": 1764123386159,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "8oVGJcGZRLM3"
   },
   "outputs": [],
   "source": [
    "# To remove English stopwords\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "\n",
    "  # Sub-models\n",
    "  embedding_model=embedding_model,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  representation_model=representation_model,\n",
    "  vectorizer_model=vectorizer_model, # Add this line\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3StbcscARLM3"
   },
   "source": [
    "Now that we are done training our model, let's see what topics were generated:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31430,
     "status": "aborted",
     "timestamp": 1764123386160,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "gT-URHlIRLM3"
   },
   "outputs": [],
   "source": [
    "# Show topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31429,
     "status": "aborted",
     "timestamp": 1764123386161,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "bTbTVp7jRLM3"
   },
   "outputs": [],
   "source": [
    "print(f\"Renderer set to '{pio.renderers.default}'\")\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31429,
     "status": "aborted",
     "timestamp": 1764123386162,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "e28ZjGZhRLM3"
   },
   "outputs": [],
   "source": [
    "gpt4o_labels = [label[0][0].split(\"\\n\")[0] for label in topic_model.get_topics(full=True)[\"GPT-40\"].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31428,
     "status": "aborted",
     "timestamp": 1764123386162,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "91guyUt_6eQT"
   },
   "outputs": [],
   "source": [
    "def get_clean_label(raw_label_string):\n",
    "    \"\"\"Extracts clean label from list or string.\"\"\"\n",
    "    # If it's already a list, just take the first element\n",
    "    if isinstance(raw_label_string, list):\n",
    "        return raw_label_string[0] if raw_label_string else \"Unlabeled Topic\"\n",
    "\n",
    "    # If it's a string, clean it up\n",
    "    if isinstance(raw_label_string, str):\n",
    "        cleaned = raw_label_string.strip()\n",
    "        # Remove brackets and quotes if present\n",
    "        cleaned = cleaned.strip(\"[]\").strip().strip(\"'\\\"\").strip()\n",
    "        return cleaned if cleaned else \"Unlabeled Topic\"\n",
    "\n",
    "    # Fallback for other types\n",
    "    return str(raw_label_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31447,
     "status": "aborted",
     "timestamp": 1764123386182,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "IKoxtPMURLM3"
   },
   "outputs": [],
   "source": [
    "# Get document info\n",
    "document_info = topic_model.get_document_info(docs)\n",
    "document_info[\"GPT-40\"] = document_info[\"GPT-40\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31447,
     "status": "aborted",
     "timestamp": 1764123386184,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "vqRZ-Hh7RLM3"
   },
   "outputs": [],
   "source": [
    "# First, let's inspect the raw content of the 'GPT-40' column\n",
    "print(\"--- Raw GPT-40 labels (before cleaning) ---\")\n",
    "display(document_info[\"GPT-40\"].head())\n",
    "\n",
    "# Now, apply the cleaning function\n",
    "all_labels = document_info[\"GPT-40\"].apply(get_clean_label)\n",
    "\n",
    "print(\"\\n--- Cleaned Labels (after cleaning) ---\")\n",
    "display(all_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31447,
     "status": "aborted",
     "timestamp": 1764123386185,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "45SHaz-0RLM3"
   },
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_barchart()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7npD2jORLM3"
   },
   "source": [
    "# Visualize Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31446,
     "status": "aborted",
     "timestamp": 1764123386186,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "kGj-LxzvRLM3",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame({\n",
    "    \"x1\": [point[0] for point in reduced_embeddings],\n",
    "    \"x2\": [point[1] for point in reduced_embeddings],\n",
    "    \"docs\": docs,\n",
    "    \"label\": all_labels\n",
    "})\n",
    "df_plot[\"docs_short\"] = df_plot[\"docs\"].str[:100] + \"...\"\n",
    "df_plot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31446,
     "status": "aborted",
     "timestamp": 1764123386188,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "NB5WDjjHRLM3"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_plot, x=\"x1\", y=\"x2\", color=\"label\", hover_data=[\"docs_short\"])\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # Change orientation to horizontal\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,           # Place the legend above the plot area\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQllvmtfRLM3"
   },
   "source": [
    "Source: https://www.williampnicholson.com/2024-02-07-topic-modelling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31446,
     "status": "aborted",
     "timestamp": 1764123386189,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "104j2SsMRLM3"
   },
   "outputs": [],
   "source": [
    "# Run the topic map visualization\n",
    "datamapplot.create_plot(\n",
    "    reduced_embeddings,\n",
    "    all_labels,\n",
    "\n",
    "    use_medoids=True,\n",
    "\n",
    "    # Follows matplotlibâ€™s 'figsize' convention.\n",
    "    # The actual size of the resulting plot (in pixels) will depend on the dots per inch (DPI)\n",
    "    # setting in matplotlib.\n",
    "    # By default that is set to 100 dots per inch for the standard backend, but it can vary.\n",
    "    figsize=(12, 12),\n",
    "    # If you really wish to have explicit control of the size of the resulting plot in pixels.\n",
    "    dpi=100,\n",
    "\n",
    "    title=\"arXiv cs.AI - Topic Analysis\",\n",
    "    sub_title=\"A Topic Map of arXiv's cs.AI sub-category based on abstracts from the arXiv api\",\n",
    "\n",
    "    # Takes a dictionary of keyword arguments that is passed through to\n",
    "    # matplotlibâ€™s 'suptitle' 'fontdict' arguments.\n",
    "    sub_title_keywords={\n",
    "        \"fontsize\":18,\n",
    "    },\n",
    "\n",
    "    # Takes a list of text labels to be highlighted.\n",
    "    # Note: these labels need to match the exact text from your labels array that you are passing in.\n",
    "    highlight_labels=[\n",
    "        \"Retinopathy Prematurity Screening\",\n",
    "    ],\n",
    "    # Takes a dictionary of keyword arguments to be applied when styling the labels.\n",
    "    highlight_label_keywords={\n",
    "        \"fontsize\": 12,\n",
    "        \"fontweight\": \"bold\",\n",
    "        \"bbox\": {\"boxstyle\":\"round\"}\n",
    "    },\n",
    "\n",
    "    # By default DataMapPlot tries to automatically choose a size for the text that will allow\n",
    "    # all the labels to be laid out well with no overlapping text. The layout algorithm will try\n",
    "    # to accommodate the size of the text you specify here.\n",
    "    label_font_size=8,\n",
    "    label_wrap_width=16,\n",
    "    label_linespacing=1.25,\n",
    "    # Default is 1.5. Generally, the values of 1.0 and 2.0 are the extremes.\n",
    "    # With 1.0 you will have more labels at the top and bottom.\n",
    "    # With 2.0 you will have more labels on the left and right.\n",
    "    label_direction_bias=1.3,\n",
    "    # Controls how large the margin is around the exact bounding box of a label, which is the\n",
    "    # bounding box used by the algorithm for collision/overlap detection.\n",
    "    # The default is 1.0, which means the margin is the same size as the label itself.\n",
    "    # Generally, the fewer labels you have the larger you can make the margin.\n",
    "    label_margin_factor=2.0,\n",
    "    # Labels are placed in rings around the core data map. This controls the starting radius for\n",
    "    # the first ring. Note: you need to provide a radius in data coordinates from the center of the\n",
    "    # data map.\n",
    "    # The defaul is selected from the data itself, based on the distance from the center of the\n",
    "    # most outlying points. Experiment and let the DataMapPlot algoritm try to clean it up.\n",
    "    label_base_radius=15.0,\n",
    "\n",
    "    # By default anything over 100,000 points uses datashader to create the scatterplot, while\n",
    "    # plots with fewer points use matplotlibâ€™s scatterplot.\n",
    "    # If DataMapPlot is using datashader then the point-size should be an integer,\n",
    "    # say 0, 1, 2, and possibly 3 at most. If however you are matplotlib scatterplot mode then you\n",
    "    # have a lot more flexibility in the point-size you can use - and in general larger values will\n",
    "    # be required. Experiment and see what works best.\n",
    "    point_size=4,\n",
    "\n",
    "    # Market type. There is only support if you are in matplotlib's scatterplot mode.\n",
    "    # https://matplotlib.org/stable/api/markers_api.html\n",
    "    marker_type=\"o\",\n",
    "\n",
    "    arrowprops={\n",
    "        \"arrowstyle\":\"wedge,tail_width=0.5\",\n",
    "        \"connectionstyle\":\"arc3,rad=0.05\",\n",
    "        \"linewidth\":0,\n",
    "        \"fc\":\"#33333377\"\n",
    "    },\n",
    "\n",
    "    add_glow=True,\n",
    "    # Takes a dictionary of keywords that are passed to the 'add_glow_to_scatterplot' function.\n",
    "    glow_keywords={\n",
    "        \"kernel_bandwidth\": 0.75,  # controls how wide the glow spreads.\n",
    "        \"kernel\": \"cosine\",        # controls the kernel type. Default is \"gaussian\". See https://scikit-learn.org/stable/modules/density.html#kernel-density.\n",
    "        \"n_levels\": 32,            # controls how many \"levels\" there are in the contour plot.\n",
    "        \"max_alpha\": 0.9,          # controls the translucency of the glow.\n",
    "    },\n",
    "\n",
    "    darkmode=False,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF, png, and svg file.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31445,
     "status": "aborted",
     "timestamp": 1764123386190,
     "user": {
      "displayName": "Ryan Goshorn",
      "userId": "14943809824370629034"
     },
     "user_tz": 480
    },
    "id": "yEKN7HwyE13X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
